# Recognizing Multimodal Entailment (ACL'2021)

The Recognizing Multimodal Entailment tutorial was held virtually at
ACL-IJCNLP 2021 on August 1st.

It gives an overview of multimodal learning, introduces a multimodal entailment
dataset, and encourages future research in the topic. For more information, https://multimodal-entailment.github.io/

A baseline model authored by [Sayak Paul](https://sayak.dev/) for this dataset is available on [Keras.io](https://keras.io/examples/nlp/multimodal_entailment), with the accompanying [repository](https://github.com/sayakpaul/Multimodal-Entailment-Baseline).


![Example of Multimodal Entailment](https://github.com/google-research-datasets/recognizing-multimodal-entailment/blob/main/multimodal_entailment.png?raw=true)

Example of multimodal entailment where texts or images alone would not suffice for semantic understanding or pairwise classifications.
